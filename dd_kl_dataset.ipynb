{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pandas as pd\n",
    "from scipy.stats import spearmanr\n",
    "from scipy.stats import bootstrap\n",
    "import numpy as np\n",
    "import re\n",
    "import os\n",
    "import shutil\n",
    "class Mutation_Set(Dataset):\n",
    "    def __init__(self, data, tokenizer, sep_len=1024):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.seq_len = sep_len\n",
    "        self.seq, self.attention_mask = tokenizer(list(self.data['mutated_sequence']), padding='max_length',\n",
    "                                                  truncation=True,\n",
    "                                                  max_length=self.seq_len).values()\n",
    "\n",
    "        target = list(data['target_seq'])\n",
    "        self.target, self.tgt_mask = tokenizer(target, padding='max_length', truncation=True,\n",
    "                                               max_length=self.seq_len).values()\n",
    "        self.score = torch.tensor(np.array(self.data['DMS_score']))\n",
    "        self.pid = np.asarray(data['PID'])\n",
    "\n",
    "        if type(list(self.data['mut_pos'])[0]) != str:\n",
    "            self.position = [[u] for u in self.data['mut_pos']]\n",
    "\n",
    "        else:\n",
    "            self.position = []\n",
    "            for u in self.data['mut_pos']:\n",
    "                p = re.findall(r'\\d+', u)\n",
    "                pos = [int(v) for v in p]\n",
    "                self.position.append(pos)\n",
    "\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.seq[idx], self.attention_mask[idx], self.target[idx],self.tgt_mask[idx] ,self.position[idx], self.score[idx], self.pid[idx]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.score)\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        seq = torch.tensor(np.array([u[0] for u in data]))\n",
    "        att_mask = torch.tensor(np.array([u[1] for u in data]))\n",
    "        tgt = torch.tensor(np.array([u[2] for u in data]))\n",
    "        tgt_mask = torch.tensor(np.array([u[3] for u in data]))\n",
    "        pos = [torch.tensor(u[4]) for u in data]\n",
    "        score = torch.tensor(np.array([u[5] for u in data]), dtype=torch.float32)\n",
    "        pid = torch.tensor(np.array([u[6] for u in data]))\n",
    "        return seq, att_mask, tgt, tgt_mask, pos, score, pid\n",
    "        \n",
    "def spearman(y_pred, y_true):\n",
    "    if np.var(y_pred) < 1e-6 or np.var(y_true) < 1e-6:\n",
    "        return 0.0\n",
    "    return spearmanr(y_pred, y_true)[0]\n",
    "\n",
    "def compute_stat(sr):\n",
    "    sr = np.asarray(sr)\n",
    "    mean = np.mean(sr)\n",
    "    std = np.std(sr)\n",
    "    sr = (sr,)\n",
    "    ci = list(bootstrap(sr, np.mean).confidence_interval)\n",
    "    return mean, std, ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EsmForMaskedLM, EsmTokenizer, EsmConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer = EsmTokenizer.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_1')\n",
    "# model = EsmForMaskedLM.from_pretrained(f'facebook/esm1v_t33_650M_UR90S_1')\n",
    "basemodel = EsmForMaskedLM.from_pretrained('facebook/esm2_t33_650M_UR50D')\n",
    "tokenizer = EsmTokenizer.from_pretrained('facebook/esm2_t33_650M_UR50D')\n",
    "# basemodel = EsmForMaskedLM.from_pretrained('facebook/esm2_t48_15B_UR50D')\n",
    "# tokenizer = EsmTokenizer.from_pretrained('facebook/esm2_t48_15B_UR50D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './substitutions_singles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import torch\n",
    "def get_pos(row):\n",
    "    pos = []\n",
    "    for mut in row['mutant'].split(':'):\n",
    "        result = int(re.findall(r'\\d+', mut)[0])\n",
    "        pos.append(result)\n",
    "    if len(pos)<=1:return pos[0]\n",
    "    else:\n",
    "        return pos\n",
    "def get_wt(seq, mut):\n",
    "    # mut的输入为A2D, or A2D:B3C\n",
    "    pos = []\n",
    "    chars = []\n",
    "    \n",
    "    for mutation in mut.split(':'):\n",
    "        original_char = mutation[0]  # 获取原始字符\n",
    "        position = int(re.findall(r'\\d+', mutation)[0])  # 获取位置\n",
    "        pos.append(position)\n",
    "        chars.append(original_char)  # 保存原始字符\n",
    "    \n",
    "    seq = list(seq)\n",
    "    for i, p in enumerate(pos):\n",
    "        seq[p - 1] = chars[i]  # 替换为原始字符\n",
    "    return ''.join(seq)\n",
    "\n",
    "def compute_score(model, seq, mask, wt, pos, tokenizer):\n",
    "    '''\n",
    "    compute mutational proxy using masked marginal probability\n",
    "    :param seq:mutant seq\n",
    "    :param mask:attention mask for input seq\n",
    "    :param wt: wild type sequence\n",
    "    :param pos:mutant position\n",
    "    :return:\n",
    "        score: mutational proxy score\n",
    "        logits: output logits for masked sequence\n",
    "    '''\n",
    "    seq = seq.to('cuda') \n",
    "    mask = mask.to('cuda') \n",
    "    wt = wt.to('cuda') \n",
    "    model = model.to('cuda')\n",
    "    device = seq.device\n",
    "    model.eval()\n",
    "\n",
    "    mask_seq = seq.clone()\n",
    "    m_id = tokenizer.mask_token_id\n",
    "\n",
    "    batch_size = int(seq.shape[0])\n",
    "    for i in range(batch_size):\n",
    "        mut_pos = pos[i]\n",
    "        mask_seq[i, mut_pos] = m_id\n",
    "\n",
    "    out = model(mask_seq, mask, output_hidden_states=True)\n",
    "    logits = out.logits\n",
    "    log_probs = torch.log_softmax(logits, dim=-1)\n",
    "    scores = torch.zeros(batch_size)\n",
    "    scores = scores.to(device)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "\n",
    "        mut_pos = pos[i]\n",
    "        score_i = log_probs[i]\n",
    "        wt_i = wt[i]\n",
    "        seq_i = seq[i]\n",
    "        scores[i] = torch.sum(score_i[mut_pos, seq_i[mut_pos]])-torch.sum(score_i[mut_pos, wt_i[mut_pos]])\n",
    "\n",
    "    return scores, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset------------BLAT_ECOLX_Jacquier_2013.csv-----------------spearman-------0.7037843352580626\n",
      "dataset------------CALM1_HUMAN_Weile_2017.csv-----------------spearman-------0.2116172465397958\n",
      "dataset------------DYR_ECOLI_Thompson_2019.csv-----------------spearman-------0.4800288357740946\n",
      "dataset------------DLG4_RAT_McLaughlin_2012.csv-----------------spearman-------0.5427728154410394\n",
      "dataset------------REV_HV1H2_Fernandes_2016.csv-----------------spearman-------0.2403806917791382\n",
      "dataset------------TAT_HV1BR_Fernandes_2016.csv-----------------spearman-------0.017450692739546466\n",
      "dataset------------RL40A_YEAST_Roscoe_2013.csv-----------------spearman-------0.598578681459522\n"
     ]
    }
   ],
   "source": [
    "# file_list = [file for  file in  os.listdir(data_path) if file.endswith('.csv')]\n",
    "\n",
    "file_list=[\n",
    "    \"BLAT_ECOLX_Jacquier_2013.csv\",\n",
    "    \"CALM1_HUMAN_Weile_2017.csv\",\n",
    "    \"DYR_ECOLI_Thompson_2019.csv\",\n",
    "    \"DLG4_RAT_McLaughlin_2012.csv\",\n",
    "    \"REV_HV1H2_Fernandes_2016.csv\",\n",
    "    \"TAT_HV1BR_Fernandes_2016.csv\",\n",
    "    \"RL40A_YEAST_Roscoe_2013.csv\",\n",
    "    \"P53_HUMAN_Giacomelli_2018_WT_Nutlin.csv\"\n",
    "]\n",
    "sr_list = []\n",
    "for csv_file in file_list:\n",
    "    df = pd.read_csv(os.path.join(data_path,csv_file))\n",
    "    df['mut_pos'] = df.apply(get_pos,axis = 1)\n",
    "    wt_seq = get_wt(df['mutated_sequence'][0],df['mutant'][0])\n",
    "    df['target_seq'] = wt_seq\n",
    "    df['PID'] = df.index\n",
    "    df = df[df['mut_pos']<1023]\n",
    "    dfset = Mutation_Set(data=df,tokenizer=tokenizer)\n",
    "\n",
    "    dfloader = DataLoader(dfset, batch_size=1, collate_fn=dfset.collate_fn, shuffle=True,num_workers=96)\n",
    "\n",
    "    basemodel.eval()\n",
    "    seq_list = []\n",
    "    score_list = []\n",
    "    gscore_list = []\n",
    "    with torch.no_grad():\n",
    "        for step, data in enumerate(dfloader):\n",
    "            seq, mask = data[0], data[1]\n",
    "            wt, wt_mask = data[2], data[3]\n",
    "            pos = data[4]\n",
    "            golden_score = data[5]\n",
    "            pid = data[6]\n",
    "\n",
    "            score, logits = compute_score(basemodel, seq, mask, wt, pos, tokenizer)\n",
    "\n",
    "            score = score.cuda()\n",
    "\n",
    "\n",
    "            score = np.asarray(score.cpu())\n",
    "            golden_score = np.asarray(golden_score.cpu())\n",
    "            score_list.extend(score)\n",
    "            gscore_list.extend(golden_score)\n",
    "    score_list = np.asarray(score_list)\n",
    "    gscore_list = np.asarray(gscore_list)\n",
    "    sr = spearman(score_list, gscore_list)\n",
    "    sr_list.append(sr)\n",
    "    print(f'dataset------------{csv_file}-----------------spearman-------{sr}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'dataset':file_list,'spearman':sr_list}).to_csv('./selected_data_esm2_spearman.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sr_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "esm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
